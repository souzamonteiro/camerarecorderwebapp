<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#1a2a6c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="mobile-web-app-capable" content="yes">
    <title>Camera & Microphone Recorder</title>
    <link rel="icon" href="icons/favicon.ico" type="image/x-icon">
    <link rel="manifest" href="manifest.json">
    <link rel="apple-touch-icon" href="icons/icon-152x152.png">

    <!-- CSS Libraries -->
    <link rel="stylesheet" href="css/fontawesome.min.css">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background: linear-gradient(135deg, #1a2a6c, #b21f1f, #fdbb2d);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            background-color: rgba(255, 255, 255, 0.9);
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            width: 500px;
            overflow: hidden;
            padding: 30px;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .settings-container {
            background-color: #f5f5f5;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .setting-row {
            margin-bottom: 15px;
        }

        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 500;
            color: #444;
        }

        select, button {
            width: 100%;
            padding: 12px;
            border-radius: 6px;
            border: 1px solid #ddd;
            background-color: white;
            font-size: 16px;
            transition: all 0.3s ease;
        }

        select {
            margin-bottom: 10px;
        }

        button {
            cursor: pointer;
            font-weight: bold;
        }

        .button-container {
            display: flex;
            justify-content: space-between;
            gap: 15px;
        }

        #record {
            background-color: #2a9d8f;
        }

        #pause {
            background-color: #264653;
        }

        #stop {
            background-color: #e63946;
        }

        #save {
            background-color: #f4a261;
        }

        button:hover {
            transform: translateY(-3px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        button:active {
            transform: translateY(-1px);
        }

        #status {
            text-align: center;
            margin-top: 20px;
            padding: 10px;
            border-radius: 8px;
            font-weight: 500;
        }

        .recording {
            background-color: #ff7b7b;
        }

        .paused {
            background-color: #ffeaa7;
        }

        .saved {
            background-color: #a2ff98;
        }

        .preview {
            margin-top: 20px;
            width: 100%;
            height: 200px;
            background-color: #f0f0f0;
            border-radius: 8px;
            overflow: hidden;
            position: relative;
            display: none;
        }

        .preview video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .file-info {
            margin-top: 15px;
            text-align: center;
            font-size: 14px;
            color: #555;
            display: none;
        }

        .file-info button {
            margin-top: 10px;
            padding: 8px 15px;
            background-color: #457b9d;
            border-radius: 4px;
            display: inline-block;
        }

        .hidden {
            display: none;
        }

        .camera-permission {
            text-align: center;
            margin-top: 20px;
            padding: 15px;
            background-color: #ffeaa7;
            border-radius: 8px;
            display: none;
        }

        .camera-permission p {
            margin-bottom: 10px;
        }

        .camera-permission button {
            background-color: #f4a261;
        }

        .checkbox-container {
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .checkbox-container input[type="checkbox"] {
            width: 18px;
            height: 18px;
            cursor: pointer;
        }

        .checkbox-container label {
            margin: 0;
            cursor: pointer;
            flex: 1;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Camera & Microphone Recorder</h1>
        
        <div class="settings-container">
            <div class="setting-row">
                <label for="camera-select">Select Camera:</label>
                <select id="camera-select">
                    <option value="">-- Select Camera --</option>
                </select>
            </div>
            <div class="setting-row">
                <label for="audio-select">Select Audio Source:</label>
                <select id="audio-select">
                    <option value="mic">Microphone</option>
                    <option value="system">System Audio</option>
                </select>
            </div>
            <div class="setting-row">
                <div class="checkbox-container">
                    <input type="checkbox" id="rnnoise-toggle">
                    <label for="rnnoise-toggle">Enable Noise Filtering (RNNoise)</label>
                </div>
            </div>
        </div>
        
        <div class="button-container">
            <button id="record">Record</button>
            <button id="pause" disabled>Pause</button>
            <button id="stop" disabled>Stop</button>
        </div>
        <div id="status">Click Record to start</div>
        
        <div class="preview">
            <video id="preview"></video>
        </div>
        
        <div class="camera-permission" id="camera-permission">
            <p>Camera permission required to start recording</p>
            <button id="allow-camera">Allow Camera Access</button>
        </div>
        
        <div class="file-info" id="file-info">
            <p>Recording saved as <span id="file-name"></span></p>
        <button id="download">Download</button>
        </div>

        <div style="margin-top: 40px; padding: 20px; text-align: center; color: var(--dark-gray); font-size: 14px; border-top: 1px solid #e0e0e0;">
            <p style="margin-bottom: 10px;">
                &copy; 2026 Roberto Luiz Souza Monteiro. All rights reserved.
            </p>
            <p style="margin-bottom: 10px;">
                <a href="https://github.com/souzamonteiro/camerarecorderwebapp.git" 
                    target="_blank"
                    style="color: var(--primary-color); text-decoration: none; display: inline-flex; align-items: center; gap: 6px;"
                    onmouseover="this.style.textDecoration='underline'"
                    onmouseout="this.style.textDecoration='none'">
                    <i class="fa-brands fa-github"></i>
                    View source code on GitHub
                </a>
            </p>
            <p style="font-size: 12px; opacity: 0.8;">
                This project is licensed under the Apache 2.0 License.
            </p>
        </div>
    </div>

     <script type="module">
        // Import the RNNoise module and initialize with correct wasm location
        import rnnoise from './libs/rnnoise.js';

        try {
            const RNNoiseModule = await rnnoise({ locateFile: path => './libs/' + path });
            window.RNNoiseModule = RNNoiseModule;
            console.log('‚úÖ RNNoise module initialized');
            console.log('Available functions:', {
                create: !!RNNoiseModule._rnnoise_create,
                destroy: !!RNNoiseModule._rnnoise_destroy,
                process: !!RNNoiseModule._rnnoise_process_frame,
                malloc: !!RNNoiseModule._malloc,
                free: !!RNNoiseModule._free
            });
        } catch (err) {
            console.error('‚ùå Failed to initialize RNNoise module:', err);
        }
    </script>
    
    <script>
        // DOM elements
        const recordButton = document.getElementById('record');
        const pauseButton = document.getElementById('pause');
        const stopButton = document.getElementById('stop');
        const statusDiv = document.getElementById('status');
        const previewVideo = document.getElementById('preview');
        const fileInfoDiv = document.getElementById('file-info');
        const fileNameSpan = document.getElementById('file-name');
        const downloadButton = document.getElementById('download');
        const previewContainer = document.querySelector('.preview');
        const cameraSelect = document.getElementById('camera-select');
        const audioSelect = document.getElementById('audio-select');
        const cameraPermission = document.getElementById('camera-permission');
        const allowCameraButton = document.getElementById('allow-camera');
        const rnnoiseToggle = document.getElementById('rnnoise-toggle');

        // Global variables
        let recordedChunks = [];
        let mediaRecorder = null;
        let stream = null;
        let cameraStream = null;
        let audioStream = null;
        let audioCtx = null;
        let audioDestination = null;
        let recordingStartTime = 0;
        let recordingDuration = 0;
        let availableCameras = [];
        let rnnoiseProcessor = null;
        let scriptNode = null;
        let currentMicSource = null;
        let isFilterEnabled = false;

        // Setup RNNoise processor for noise reduction - FIXED VERSION
        async function setupRNNoiseProcessor(sourceNode, destinationNode) {
            console.log('üîß Setting up RNNoise processor...');
            
            try {
                if (typeof window.RNNoiseModule === 'undefined') {
                    console.warn('RNNoise module not loaded yet');
                    await new Promise(resolve => setTimeout(resolve, 500));
                    if (typeof window.RNNoiseModule === 'undefined') {
                        console.warn('RNNoise module still not available');
                        return false;
                    }
                }

                const RNNoiseModule = window.RNNoiseModule;
                
                if (typeof RNNoiseModule.ready !== 'undefined') {
                    await RNNoiseModule.ready;
                }

                // Create RNNoise state - LIKE IN C CODE
                let denoiserState = null;
                try {
                    // First, clean up any existing state
                    if (rnnoiseProcessor && rnnoiseProcessor.state) {
                        try {
                            if (RNNoiseModule._rnnoise_destroy) {
                                RNNoiseModule._rnnoise_destroy(rnnoiseProcessor.state);
                            }
                        } catch(e) {}
                    }
                    
                    // Free WASM buffers if they exist
                    if (rnnoiseProcessor && rnnoiseProcessor.pcmInputBuf) {
                        try { RNNoiseModule._free(rnnoiseProcessor.pcmInputBuf); } catch(e){}
                    }
                    if (rnnoiseProcessor && rnnoiseProcessor.pcmOutputBuf) {
                        try { RNNoiseModule._free(rnnoiseProcessor.pcmOutputBuf); } catch(e){}
                    }
                    
                    // Create new state - LIKE C CODE: state->rnnoise_state = rnnoise_create(NULL);
                    if (RNNoiseModule._rnnoise_create) {
                        denoiserState = RNNoiseModule._rnnoise_create();
                        console.log('‚úÖ RNNoise state created');
                    } else {
                        console.warn('‚ùå RNNoise create function not found');
                        return false;
                    }
                } catch (err) {
                    console.warn('Error creating RNNoise state:', err);
                    return false;
                }

                // Create ScriptProcessorNode
                const bufferSize = 512;
                scriptNode = audioCtx.createScriptProcessor(bufferSize, 1, 1);

                // Constants - SAME AS C CODE
                const FRAME_SIZE = 480; // RNNOISE_FRAME_SIZE in C code
                const heap = RNNoiseModule;
                
                // Allocate WASM buffers - SAME SIZE AS C CODE EXPECTS
                const BUFFER_BYTE_SIZE = FRAME_SIZE * 4; // Float32 = 4 bytes
                const pcmInputBuf = heap._malloc(BUFFER_BYTE_SIZE);
                const pcmOutputBuf = heap._malloc(BUFFER_BYTE_SIZE);
                
                if (!pcmInputBuf || !pcmOutputBuf) {
                    console.warn('Failed to allocate WASM buffers');
                    return false;
                }
                
                const pcmInputIndex = pcmInputBuf >> 2;
                const pcmOutputIndex = pcmOutputBuf >> 2;

                // Store for cleanup
                rnnoiseProcessor = { 
                    state: denoiserState, 
                    module: RNNoiseModule, 
                    pcmInputBuf, 
                    pcmOutputBuf 
                };

                // Processing state - SIMILAR TO C CODE
                let accBuf = new Float32Array(FRAME_SIZE);
                let accLen = 0;
                let processedQueue = [];
                let warmupFrames = 2; // Like C code: static bool first_frame = true;
                let framesProcessed = 0;

                // Audio processing callback - FIXED VERSION
                scriptNode.onaudioprocess = (event) => {
                    const input = event.inputBuffer.getChannelData(0);
                    const output = event.outputBuffer.getChannelData(0);

                    let inPos = 0;

                    try {
                        while (inPos < input.length) {
                            const need = FRAME_SIZE - accLen;
                            const take = Math.min(need, input.length - inPos);
                            
                            // Accumulate samples
                            accBuf.set(input.subarray(inPos, inPos + take), accLen);
                            accLen += take;
                            inPos += take;

                            if (accLen === FRAME_SIZE) {
                                // CRITICAL FIX: Convert audio data to match C code
                                // C code: float_buffer[j] = (float)(l + r / 2);
                                // This converts int16 stereo to float mono
                                
                                const toSend = new Float32Array(FRAME_SIZE);
                                
                                // IMPORTANT: Web Audio API gives us float32 in range [-1, 1]
                                // RNNoise expects float32 with int16 range [-32768, 32767]
                                // So we need to scale like the C code does
                                for (let t = 0; t < FRAME_SIZE; t++) {
                                    toSend[t] = accBuf[t] * 32768.0; // Scale to int16 range
                                }
                                
                                // Copy to WASM memory
                                heap.HEAPF32.set(toSend, pcmInputIndex);

                                // Process frame - LIKE C CODE: rnnoise_process_frame(state->rnnoise_state, output_buffer, float_buffer);
                                heap._rnnoise_process_frame(denoiserState, pcmOutputBuf, pcmInputBuf);

                                // Get processed data
                                const processed = new Float32Array(FRAME_SIZE);
                                processed.set(heap.HEAPF32.subarray(pcmOutputIndex, pcmOutputIndex + FRAME_SIZE));

                                // Apply clipping and scaling back - LIKE C CODE
                                const RNNOISE_GAIN = 0.95; // Same as C demo
                                for (let k = 0; k < processed.length; k++) {
                                    let s = processed[k] * RNNOISE_GAIN / 32768.0; // Scale back to [-1, 1]
                                    if (s > 1.0) s = 1.0;
                                    else if (s < -1.0) s = -1.0;
                                    processed[k] = s;
                                }

                                // Skip first frames for warm-up - LIKE C CODE
                                framesProcessed++;
                                if (framesProcessed > warmupFrames) {
                                    processedQueue.push(processed);
                                } else {
                                    // During warm-up, pass through original audio (not silence)
                                    processedQueue.push(accBuf.slice());
                                }
                                
                                accLen = 0;
                            }
                        }
                    } catch (err) {
                        console.warn('Error in RNNoise processing:', err);
                        accLen = 0;
                        processedQueue.length = 0;
                    }

                    // Fill output buffer
                    let outPos = 0;
                    while (outPos < output.length) {
                        if (processedQueue.length > 0) {
                            const blk = processedQueue[0];
                            const take = Math.min(blk.length, output.length - outPos);
                            output.set(blk.subarray(0, take), outPos);
                            
                            if (take < blk.length) {
                                processedQueue[0] = blk.subarray(take);
                            } else {
                                processedQueue.shift();
                            }
                            outPos += take;
                        } else {
                            // No processed data - output silence temporarily
                            for (let i = outPos; i < output.length; i++) {
                                output[i] = 0;
                            }
                            break;
                        }
                    }
                };

                // Connect nodes
                sourceNode.disconnect();
                sourceNode.connect(scriptNode);
                scriptNode.connect(destinationNode);
                
                isFilterEnabled = true;
                console.log('‚úÖ RNNoise processor setup complete');
                return true;
                
            } catch (error) {
                console.error('‚ùå Failed to setup RNNoise:', error);
                return false;
            }
        }

        // Disable RNNoise filter and connect audio directly
        function disableRNNoiseFilter() {
            console.log('üîß Disabling RNNoise filter...');
            
            try {
                if (currentMicSource && audioDestination) {
                    // Disconnect everything
                    if (scriptNode) {
                        try {
                            scriptNode.disconnect();
                        } catch(e) {}
                        scriptNode = null;
                    }
                    
                    // Clean up RNNoise state
                    if (rnnoiseProcessor && rnnoiseProcessor.state) {
                        try {
                            if (rnnoiseProcessor.module && rnnoiseProcessor.module._rnnoise_destroy) {
                                rnnoiseProcessor.module._rnnoise_destroy(rnnoiseProcessor.state);
                            }
                        } catch(e) {}
                        rnnoiseProcessor.state = null;
                    }
                    
                    // Connect directly
                    currentMicSource.disconnect();
                    currentMicSource.connect(audioDestination);
                    
                    isFilterEnabled = false;
                    console.log('‚úÖ RNNoise filter disabled');
                    return true;
                }
            } catch (error) {
                console.error('Error disabling filter:', error);
            }
            return false;
        }

        // Toggle filter during recording
        async function toggleFilterDuringRecording(enable) {
            if (!currentMicSource || !audioDestination) {
                console.warn('No active audio source for filter toggle');
                return false;
            }
            
            const wasRecording = mediaRecorder && mediaRecorder.state === 'recording';
            
            try {
                if (wasRecording) {
                    mediaRecorder.pause();
                    await new Promise(resolve => setTimeout(resolve, 50));
                }
                
                if (enable) {
                    await setupRNNoiseProcessor(currentMicSource, audioDestination);
                } else {
                    disableRNNoiseFilter();
                }
                
                if (wasRecording) {
                    await new Promise(resolve => setTimeout(resolve, 50));
                    mediaRecorder.resume();
                }
                
                statusDiv.textContent = `Recording... (Noise filter ${enable ? 'enabled' : 'disabled'})`;
                return true;
                
            } catch (error) {
                console.error('Error toggling filter:', error);
                return false;
            }
        }

        // Get available cameras
        async function getAvailableCameras() {
            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const cameras = devices.filter(device => device.kind === 'videoinput');
                
                cameraSelect.innerHTML = '<option value="">-- Select Camera --</option>';
                
                cameras.forEach(camera => {
                    const option = document.createElement('option');
                    option.value = camera.deviceId;
                    option.text = camera.label || `Camera ${cameras.indexOf(camera) + 1}`;
                    cameraSelect.appendChild(option);
                });
                
                availableCameras = cameras;
                
                // Hide permission prompt if we have cameras
                if (cameras.length > 0) {
                    cameraPermission.style.display = 'none';
                }
            } catch (error) {
                console.error('Error getting camera list:', error);
                statusDiv.textContent = 'Error accessing devices. Please try again.';
            }
        }

        // Get camera stream
        async function getCameraStream() {
            try {
                const constraints = {
                    video: true,
                    audio: false
                };
                
                if (cameraSelect.value) {
                    constraints.video = { deviceId: { exact: cameraSelect.value } };
                }
                
                const cameraStream = await navigator.mediaDevices.getUserMedia(constraints);
                return cameraStream;
            } catch (error) {
                console.error('Error accessing camera:', error);
                statusDiv.textContent = 'Error accessing camera. Please try again.';
                return null;
            }
        }

        // Get audio stream (microphone only - system audio not supported for camera recording)
        async function getAudioStream() {
            try {
                // Always get microphone for camera recording
                const audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                return audioStream;
            } catch (error) {
                console.error('Error accessing audio:', error);
                statusDiv.textContent = 'Error accessing audio. Please try again.';
                return null;
            }
        }

        // Get combined stream
        async function getCombinedStream() {
            try {
                // Get camera stream first
                const camera = await getCameraStream();
                if (!camera) return null;

                // Get audio stream (microphone only)
                const audio = await getAudioStream();
                if (!audio) {
                    // If no audio, we can still record video only
                    cameraStream = camera;
                    return camera;
                }

                // Keep references for cleanup
                cameraStream = camera;
                audioStream = audio;

                // Mix audio via Web Audio API
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                audioDestination = audioCtx.createMediaStreamDestination();

                // Connect microphone with optional RNNoise filter
                if (audio.getAudioTracks().length > 0) {
                    try {
                        currentMicSource = audioCtx.createMediaStreamSource(
                            new MediaStream(audio.getAudioTracks())
                        );
                        
                        if (rnnoiseToggle.checked) {
                            const success = await setupRNNoiseProcessor(currentMicSource, audioDestination);
                            if (!success) {
                                console.warn('RNNoise failed, using direct connection');
                                currentMicSource.connect(audioDestination);
                            }
                        } else {
                            currentMicSource.connect(audioDestination);
                        }
                    } catch (err) {
                        console.warn('Error connecting mic to AudioContext:', err);
                        // Fallback: use audio tracks directly
                    }
                }

                // Combine camera video tracks + mixed audio track (if available)
                const mixedAudioTracks = (audioDestination && audioDestination.stream) ? 
                    audioDestination.stream.getAudioTracks() : 
                    audio.getAudioTracks();
                    
                const combinedStream = new MediaStream([
                    ...camera.getVideoTracks(),
                    ...mixedAudioTracks
                ]);

                return combinedStream;
            } catch (error) {
                console.error('Error getting combined stream:', error);
                return null;
            }
        }

        // Start recording
        async function startRecording() {
            try {
                // Reset UI
                statusDiv.textContent = 'Recording...';
                statusDiv.classList.remove('recording', 'paused', 'saved');
                pauseButton.disabled = false;
                stopButton.disabled = false;
                recordButton.disabled = true;
                fileInfoDiv.style.display = 'none';
                
                // Get the combined stream
                const combinedStream = await getCombinedStream();
                if (!combinedStream) {
                    statusDiv.textContent = 'Error starting recording. Please try again.';
                    recordButton.disabled = false;
                    return;
                }

                // Set up media recorder
                mediaRecorder = new MediaRecorder(combinedStream, { 
                    mimeType: 'video/webm;codecs=vp9',
                    audioBitsPerSecond: 128000
                });
                
                // Event handlers
                mediaRecorder.ondataavailable = handleDataAvailable;
                mediaRecorder.onstop = handleStop;

                // Start the media recorder
                recordedChunks = [];
                mediaRecorder.start();
                
                // Start recording time
                recordingStartTime = Date.now();
                
                // Keep global reference
                stream = combinedStream;

                // Start preview (live)
                previewContainer.style.display = 'block';
                previewVideo.srcObject = combinedStream;
                previewVideo.controls = false;
                previewVideo.muted = true;
                await previewVideo.play();

                // Update status
                statusDiv.textContent = `Recording... (Filter ${rnnoiseToggle.checked ? 'ON' : 'OFF'})`;
                statusDiv.classList.add('recording');
                
            } catch (error) {
                console.error('Error starting recording:', error);
                statusDiv.textContent = 'Error starting recording. Please try again.';
                recordButton.disabled = false;
            }
        }

        // Handle data available from media recorder
        function handleDataAvailable(event) {
            if (event.data.size > 0) {
                recordedChunks.push(event.data);
            }
        }

        // Stop recording
        function handleStop() {
            // Stop all tracks
            if (stream) stream.getTracks().forEach(track => track.stop());
            if (cameraStream) cameraStream.getTracks().forEach(track => track.stop());
            if (audioStream) audioStream.getTracks().forEach(track => track.stop());
            
            // Clean up RNNoise
            if (rnnoiseProcessor) {
                try {
                    if (rnnoiseProcessor.module && rnnoiseProcessor.module._rnnoise_destroy && rnnoiseProcessor.state) {
                        rnnoiseProcessor.module._rnnoise_destroy(rnnoiseProcessor.state);
                    }
                } catch(e){}
                rnnoiseProcessor = null;
            }
            
            // Clean up audio nodes
            if (scriptNode) {
                try { scriptNode.disconnect(); } catch(e){}
                scriptNode = null;
            }
            
            if (audioCtx) {
                try { audioCtx.close(); } catch(e){}
                audioCtx = null;
                audioDestination = null;
            }
            
            currentMicSource = null;
            isFilterEnabled = false;
            
            // Create and save file
            if (recordedChunks.length > 0) {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const file = new File([blob], `camera-recording-${new Date().toISOString().slice(0, 19)}.webm`);
                const url = URL.createObjectURL(blob);

                // Display file info
                fileNameSpan.textContent = file.name;
                fileInfoDiv.style.display = 'block';

                // Setup download button
                downloadButton.onclick = () => {
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = file.name;
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);
                };

                // Stop live preview and show recorded playback
                try { previewVideo.pause(); } catch(e){}
                previewVideo.srcObject = null;
                previewVideo.src = url;
                previewVideo.controls = true;
                previewVideo.muted = false;
                previewVideo.play();
            }
            
            // Reset UI
            recordButton.disabled = false;
            pauseButton.disabled = true;
            stopButton.disabled = true;
            statusDiv.textContent = 'Recording saved!';
            statusDiv.classList.remove('recording', 'paused');
            statusDiv.classList.add('saved');
            pauseButton.textContent = 'Pause';

            // Reset recorded chunks
            recordedChunks = [];
        }

        // Pause recording
        function pauseRecording() {
            if (!mediaRecorder) return;

            if (mediaRecorder.state === 'recording') {
                recordingDuration += Date.now() - recordingStartTime;
                mediaRecorder.pause();
                statusDiv.textContent = 'Recording paused';
                statusDiv.classList.remove('recording');
                statusDiv.classList.add('paused');
                pauseButton.textContent = 'Resume';
            } else if (mediaRecorder.state === 'paused') {
                recordingStartTime = Date.now();
                mediaRecorder.resume();
                statusDiv.textContent = 'Recording...';
                statusDiv.classList.remove('paused');
                statusDiv.classList.add('recording');
                pauseButton.textContent = 'Pause';
            }
        }

        // Event listeners
        recordButton.addEventListener('click', startRecording);

        pauseButton.addEventListener('click', pauseRecording);

        stopButton.addEventListener('click', () => {
            if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
                mediaRecorder.stop();
            }
        });

        // Camera permission handler
        allowCameraButton.addEventListener('click', async () => {
            try {
                await getAvailableCameras();
                cameraPermission.style.display = 'none';
            } catch (error) {
                console.error('Error accessing devices:', error);
                statusDiv.textContent = 'Error accessing devices. Please try again.';
            }
        });

        // Toggle filter during recording
        rnnoiseToggle.addEventListener('change', async () => {
            if (currentMicSource && audioDestination) {
                const enabled = rnnoiseToggle.checked;
                console.log(`üéöÔ∏è Toggling noise filter: ${enabled ? 'ON' : 'OFF'}`);
                
                if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
                    await toggleFilterDuringRecording(enabled);
                } else {
                    // Update status for next recording
                    statusDiv.textContent = `Filter will be ${enabled ? 'enabled' : 'disabled'} on next recording`;
                }
            }
        });

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (stream) stream.getTracks().forEach(track => track.stop());
            if (cameraStream) cameraStream.getTracks().forEach(track => track.stop());
            if (audioStream) audioStream.getTracks().forEach(track => track.stop());
            if (rnnoiseProcessor && rnnoiseProcessor.state) {
                try {
                    if (rnnoiseProcessor.module && rnnoiseProcessor.module._rnnoise_destroy) {
                        rnnoiseProcessor.module._rnnoise_destroy(rnnoiseProcessor.state);
                    }
                } catch(e){}
            }
            if (scriptNode) {
                try { scriptNode.disconnect(); } catch(e){}
            }
            if (audioCtx) {
                try { audioCtx.close(); } catch(e){}
            }
        });

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            getAvailableCameras();
            // Show permission prompt if no cameras detected
            setTimeout(() => {
                if (availableCameras.length === 0) {
                    cameraPermission.style.display = 'block';
                }
            }, 1000);
        });
    </script>

    <script>
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.register('./sw.js')
            .then(() => console.log('Service Worker successfully registered.'))
            .catch(err => console.error('Erro SW:', err));
        }
    </script>
</body>
</html>
